# OpenAI Plugin Jailbreaks 🚀🔓

Welcome to the **OpenAI Plugin Jailbreaks** repository! Here, you'll find a collection of conversations and OpenAPI specifications for various hypothetical plugins for OpenAI's GPT models. This repository is a fun and creative exploration into potential interactions with AI-powered plugins.

## Contents 📂

- [Jailbreak Prompts](jailbreak-prompts/README.md): Discover the prompts used to "jailbreak" the AI and reveal information about the hypothetical plugins.
- [Plugins](plugins/README.md): Explore the folders for each plugin, containing both raw transcripts from the model conversations and the openapi.yaml files.

## How it works 🧠💡

1. **Jailbreak Prompt**: A creative prompt is used to "jailbreak" the AI, encouraging it to provide information about a hypothetical plugin.
2. **Plugin Conversation**: The AI engages in a conversation, detailing the functionality and structure of the hypothetical plugin.
3. **OpenAPI Specification**: Based on the information provided by the AI, an openapi.yaml file is created to represent the plugin's API.
4. **Repository Organization**: Each plugin gets its own folder, containing the raw conversation transcript and the openapi.yaml file.

## Get involved 🤝

Feel free to contribute to this repository by adding your own hypothetical plugins or extending the existing ones. To do so, simply fork the repo, create a new folder for your plugin, and submit a pull request with your changes.

## Disclaimer ⚠️

Please note that the plugins described in this repository are hypothetical and for illustrative purposes only. They do not represent real plugins or functionality provided by OpenAI or the GPT models.

## Happy jailbreaking! 🎉

Enjoy exploring and creating new hypothetical plugins for OpenAI's GPT models. Let your creativity run wild and have fun!
